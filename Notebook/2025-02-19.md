# ILR | 2025-02-19

## Learning stable spatio-temporal DS controller

- DMP: Dynamic movement primitives
- SEDS, 2011; DMP, 2013
- ~Works on a second order dynamical systems

### Non-linear spring damper systems

#### Canonical system

$$
\tau \dot x = -\alpha_x x
$$

#### Transformed system

- Has a forcing function

$$
\tau^2 \ddot y = \underbrace{ \alpha_y (\beta_y (g - y)) }_{\text{stifness term}} + \underbrace{ \tau (0 - \dot y) }_{\text{damping term}} + \underbrace{ f(x) }_{\text{forcing function}}
$$

- $\tau \to$ ensures temporal generalisation
- Spatio-temporal generalisation

### Mass spring damper model

$$
\tilde x = x - x_v
\\
f = k \tilde x
$$

### Second order system (Canonical form)

$$
\ddot x + 2 \zeta \dot x + \omega_n^2 x = 0
$$

#### Solution

$$
x = \frac{-2 \zeta \omega_n \pm \sqrt{4 \omega_n^2 (\zeta^2 - 1)}}{2}
$$

#### Effects of damping

| Damping Condition | System Behavior         |
|-------------------|-------------------------|
| $\zeta > 1$       | Overdamped system       |
| $\zeta = 1$       | Critically damped system|
| $0 < \zeta < 1$   | Underdamped system      |
| $\zeta = 0$       | No damping              |
| $\zeta < 0$       | Instable system         |

---

- Basic attractor
  - ~Critically damped system

$$
\sim \alpha_y = -4 \beta_y
$$

- Critically damped system ensures reaching goal in an optimal way
- Interim clocks
  - ~ A tool/technique

$$
\ddot y = \alpha_y (\beta_y (g - y) - \dot y) + f
$$

$$
\dot x = \alpha_x x
$$

$$
f(x, g) = \frac{\sum_{i = 1}^{N} \psi_i w_i x}{\sum_{i = 1}^{N} \psi_i}
$$

- Uses a locally weighted regression

### Temporal scaling

- Introducing a temporaling scaling parameter

$$
\tau = \frac{t}{\widehat t}
\\
\implies
\dot y = \frac{d y}{dt} = \frac{d y}{d \widehat t} \frac{d \widehat t}{dt} = \frac{1}{\tau} \frac{d y}{d \widehat t}
$$

- Effects of changing $\tau$
  - $\tau = 1$ gives back the originial motion
  - Smaller $\tau$ gives faster movements
  - Larger $\tau$ gives slower movements

- The canonical system then becomes

  $$
  \dot x = - \frac{\alpha_x}{\tau} x
  $$
  
  whose solution now is
  
  $$
  x(t) = e^{-\cfrac{\alpha_x}{\tau} t}
  $$

- Sum of basis functions
  
  $$
  f(x, g) = \frac{\sum_{i = 1}^{N} \psi_i w_i}{\sum_{i = 1}^{N} \psi_i} x (g - y_0)
  \\
  \psi_i = \exp(- h_i {(x - c_i)}^2)
  $$

  - $\psi_i \to$ Gaussian basis functions, chosen with a mean and variance
  
    $$
    f_d = \ddot y_d - \alpha_y (\beta_y (g - y) - \dot y)
    $$

  - One-shot learning possible

  $$
  w_i = \frac{s^\top \psi_i f_d}{s^\top \psi_i s}
  $$

  $$
  s = \begin{bmatrix}
  x_{t_0} (g - y_0) \\
  x_{t_1} (g - y_0) \\
  \vdots \\
  x_{t_N} (g - y_0) \\
  \end{bmatrix}
  $$

  $$
  \psi_i = \text{diag} (\psi_i(1), \psi_i(2), \dots, \psi_i(N))
  $$

  - Forcing function goes to $0$ (at end point?) by using Gaussian, ensuring stable attractor.
  
- Spatial scaling

---

- References
  - <https://pubmed.ncbi.nlm.nih.gov/23148415/>
  - <https://arxiv.org/abs/2102.03861>

---

